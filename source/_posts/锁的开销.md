title: 锁的开销
---

我在学习多线程编程的时候，得到的第一条关于性能忠告是锁的开销很大。由此引发了三个问题：有多大，为什么以及如何尽量避免。

------------------------------------------------------------

在计算机里，“很大”实在是一个太过于模糊的概念。比如同样是函数调用，在一个移动APP的大部分地方，我们会鼓励尽量把大的函数拆分以便于阅读和理解代码，而如果这个APP包含一个视频codec，里边为了效率会尽量避免在循环里做函数调用，甚至会把循环展开减少跳转的次数来优化处理器流水线。所以笼统的说某个操作“开销很大”没太大的意义，只有比较精确的测量出实际的开销有多大，我们才能决定使用的方式和优化机制。

锁开销的测量
------

我们针对的是多线程环境下的锁机制，基于linux做测试。每种编程语言提供的锁机制都不太一样，不过无论如何，最终都会落实到两种机制上，一是处理器提供的原子操作指令（现在一般是CAS—compare and swap），处理器会用轮询的方式试图获得锁，在处理器（包括多核）架构里这是必不可少的机制；二是内核提供的锁系统调用，在被锁住的时候会把当前线程置于睡眠（阻塞）状态。

实际上我们在编程的时候并不会直接调用这两种机制，而是使用编程语言所带函数库里的锁方法，锁方法内部混合使用这两种机制。以pthread库（NPTL）的pthread\_mutex来举例，一把锁本质上只是一个int类型的变量，占用4个字节内存并且内存边界按4字节对齐。加锁的时候先用tryLock方法（内部使用的是CAS指令）来尝试获得锁，如果无法获得锁，则调用系统调用sys\_futex来试图获得锁，这时候如果还不能获得锁，当前线程就会被阻塞。

java之类的语言会使用看起来和pthread\_mutex很不一样的锁机制（比如synchronise），但是实际上底层还是通过pthread\_mutex的方法来加锁，或者是混合使用CAS和sys\_futex—和pthread\_mutex差不多。

所以很容易得到一个结论，如果锁不存在冲突，每次获得锁和释放锁的处理器开销仅仅是CAS指令的开销，在x86-64处理器上，这个开销只比一次内存访问（无cache）高一点（大概是1.3倍）。以我现在在使用的MacBoolPro为例，内存的规格是DDR3-1600，实际的时钟频率为800MHz，每个时钟周期1.25ns；突发的内存访问存在8个时钟周期的延迟（这个延迟的缩写也是CAS，参考[https://en.wikipedia.org/wiki/CAS\_latency](https://en.wikipedia.org/wiki/CAS_latency)），也就是10ns的内存访问延迟，这样算下来，CAS指令的开销大改是十多个ns。

确定一件事情最好的方法是实际测试和观测它，让我们写一段代码来测试无冲突时锁的开销，核心代码大概是这样：

```c
while(c < MAX) {
	pthread_mutex_lock(&mutex);
	c = c + 1;
	pthread_mutex_unlock(&mutex);
}
```

其实就是循环的lock和unlock。运行五亿次以后，计算耗时为14.5s左右，平摊到每次加锁/解锁操作大改是14ns每次加锁/解锁（扣除很少的一点循环开销）。这个数值和CAS指令的理论开销吻合得很好。

to be continued ...
